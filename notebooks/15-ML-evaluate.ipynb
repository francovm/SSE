{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spot check on raw data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pylab import rcParams\n",
    "# from keras.callbacks import EarlyStopping\n",
    "\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>n</th>\n",
       "      <th>u</th>\n",
       "      <th>Events</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-12.28</td>\n",
       "      <td>-92.30</td>\n",
       "      <td>-9.23</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-12.58</td>\n",
       "      <td>-92.54</td>\n",
       "      <td>-11.31</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-13.16</td>\n",
       "      <td>-92.24</td>\n",
       "      <td>-8.02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-13.21</td>\n",
       "      <td>-92.20</td>\n",
       "      <td>-11.51</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-12.92</td>\n",
       "      <td>-93.19</td>\n",
       "      <td>-10.20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       x      n      u  Events\n",
       "0 -12.28 -92.30  -9.23     0.0\n",
       "1 -12.58 -92.54 -11.31     0.0\n",
       "2 -13.16 -92.24  -8.02     0.0\n",
       "3 -13.21 -92.20 -11.51     0.0\n",
       "4 -12.92 -93.19 -10.20     0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "SEED = 123 #used to help randomly select the data points\n",
    "DATA_SPLIT_PCT = 0.3\n",
    "\n",
    "# load  dataset\n",
    "df = pd.read_csv('/home/francovm/Projects/SSE/data/processed/input_data.csv', sep='\\t', encoding='utf-8')\n",
    "df_MAHI = pd.read_csv('/home/francovm/Projects/SSE/data/processed/MAHI.csv', sep='\\t', encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(229716, 3) (229716,) (4330, 3) (4330,)\n"
     ]
    }
   ],
   "source": [
    "input_X = df.loc[:, df.columns != 'Events'].values  # converts the df to a numpy array\n",
    "input_y = df['Events'].values\n",
    "\n",
    "n_features = 3  # number of features\n",
    "\n",
    "\n",
    "input_X_MAHI = df_MAHI.loc[:, df_MAHI.columns != 'Events'].values  # converts the df to a numpy array\n",
    "\n",
    "input_y_MAHI = df_MAHI['Events'].values\n",
    "\n",
    "print(input_X.shape,input_y.shape,input_X_MAHI.shape,input_y_MAHI.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into Test, valid and train\n",
    "\n",
    "trainX, testX, trainy, testy = train_test_split(np.array(input_X), np.array(input_y), test_size=DATA_SPLIT_PCT, random_state=SEED)\n",
    "\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=DATA_SPLIT_PCT, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160801, 3) (160801,) (68915, 3) (68915,)\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape, trainy.shape, testX.shape, testy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dict of standard models to evaluate {name:object}\n",
    "def define_models(models=dict()):\n",
    "\t# nonlinear models\n",
    "\tmodels['knn'] = KNeighborsClassifier(n_neighbors=7)\n",
    "\tmodels['cart'] = DecisionTreeClassifier()\n",
    "\tmodels['svm'] = SVC()\n",
    "\tmodels['bayes'] = GaussianNB()\n",
    "\t# ensemble models\n",
    "\tmodels['bag'] = BaggingClassifier(n_estimators=100)\n",
    "\tmodels['rf'] = RandomForestClassifier(n_estimators=100)\n",
    "\tmodels['et'] = ExtraTreesClassifier(n_estimators=100)\n",
    "\tmodels['gbm'] = GradientBoostingClassifier(n_estimators=100)\n",
    "\tprint('Defined %d models' % len(models))\n",
    "\treturn models\n",
    "\n",
    "# evaluate a single model\n",
    "def evaluate_model(trainX, trainy, testX, testy, model):\n",
    "\t# fit the model\n",
    "\tmodel.fit(trainX, trainy)\n",
    "\t# make predictions\n",
    "\tyhat = model.predict(testX)\n",
    "\t# evaluate predictions\n",
    "\taccuracy = accuracy_score(testy, yhat)\n",
    "\treturn accuracy * 100.0\n",
    "\n",
    "# evaluate a dict of models {name:object}, returns {name:score}\n",
    "def evaluate_models(trainX, trainy, input_X_MAH, input_y_MAHI, models):\n",
    "\tresults = dict()\n",
    "\tfor name, model in models.items():\n",
    "\t\t# evaluate the model\n",
    "\t\tresults[name] = evaluate_model(trainX, trainy, input_X_MAH, input_y_MAHI, model)\n",
    "\t\t# show process\n",
    "\t\tprint('>%s: %.3f' % (name, results[name]))\n",
    "\treturn results\n",
    "\n",
    "# print and plot the results\n",
    "def summarize_results(results, maximize=True):\n",
    "\t# create a list of (name, mean(scores)) tuples\n",
    "\tmean_scores = [(k,v) for k,v in results.items()]\n",
    "\t# sort tuples by mean score\n",
    "\tmean_scores = sorted(mean_scores, key=lambda x: x[1])\n",
    "\t# reverse for descending order (e.g. for accuracy)\n",
    "\tif maximize:\n",
    "\t\tmean_scores = list(reversed(mean_scores))\n",
    "\tprint()\n",
    "\tfor name, score in mean_scores:\n",
    "\t\tprint('Name=%s, Score=%.3f' % (name, score))\n",
    "\n",
    "# load dataset\n",
    "# trainX, trainy, testX, testy = load_dataset()\n",
    "# get model list\n",
    "# models = define_models()\n",
    "# # evaluate models\n",
    "# results = evaluate_models(trainX, trainy, testX, testy, models)\n",
    "# # summarize results\n",
    "# summarize_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 8 models\n",
      ">knn: 95.814\n",
      ">cart: 93.096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/francovm/anaconda3/envs/keras/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">svm: 95.833\n",
      ">bayes: 95.734\n",
      ">bag: 95.857\n",
      ">rf: 95.867\n",
      ">et: 95.804\n",
      ">gbm: 95.788\n",
      "\n",
      "Name=rf, Score=95.867\n",
      "Name=bag, Score=95.857\n",
      "Name=svm, Score=95.833\n",
      "Name=knn, Score=95.814\n",
      "Name=et, Score=95.804\n",
      "Name=gbm, Score=95.788\n",
      "Name=bayes, Score=95.734\n",
      "Name=cart, Score=93.096\n"
     ]
    }
   ],
   "source": [
    "models = define_models()\n",
    "# evaluate models\n",
    "results = evaluate_models(trainX, trainy, testX, testy, models)\n",
    "# summarize results\n",
    "summarize_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
