{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pylab import rcParams\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(7)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(11)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 123 #used to help randomly select the data points\n",
    "DATA_SPLIT_PCT = 0.2\n",
    "\n",
    "rcParams['figure.figsize'] = 8, 6\n",
    "LABELS = [\"Normal\",\"Break\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load  dataset\n",
    "df = pd.read_csv('/home/francovm/Projects/SSE/data/processed/input_data.csv', sep='\\t', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>n</th>\n",
       "      <th>u</th>\n",
       "      <th>Events</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-12.28</td>\n",
       "      <td>-92.30</td>\n",
       "      <td>-9.23</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-12.58</td>\n",
       "      <td>-92.54</td>\n",
       "      <td>-11.31</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-13.16</td>\n",
       "      <td>-92.24</td>\n",
       "      <td>-8.02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-13.21</td>\n",
       "      <td>-92.20</td>\n",
       "      <td>-11.51</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-12.92</td>\n",
       "      <td>-93.19</td>\n",
       "      <td>-10.20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       x      n      u  Events\n",
       "0 -12.28 -92.30  -9.23     0.0\n",
       "1 -12.58 -92.54 -11.31     0.0\n",
       "2 -13.16 -92.24  -8.02     0.0\n",
       "3 -13.21 -92.20 -11.51     0.0\n",
       "4 -12.92 -93.19 -10.20     0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(229716, 3) (229716,)\n"
     ]
    }
   ],
   "source": [
    "input_X = df.loc[:, df.columns != 'Events'].values  # converts the df to a numpy array\n",
    "input_y = df['Events'].values\n",
    "\n",
    "n_features = input_X.shape[1]  # number of features\n",
    "\n",
    "print(input_X.shape,input_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporalize(X, y, lookback):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(input_X)-lookback-1):\n",
    "        t = []\n",
    "        for j in range(1,lookback+1):\n",
    "            # Gather past records upto the lookback period\n",
    "            t.append(input_X[[(i+j+1)], :])\n",
    "        X.append(t)\n",
    "        y.append(input_y[i+lookback+1])\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporalize the data\n",
    "lookback = 20\n",
    "X, y = temporalize(X = input_X, y = input_y, lookback = lookback)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into Test, valid and train\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(X), np.array(y), test_size=DATA_SPLIT_PCT, random_state=SEED)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=DATA_SPLIT_PCT, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the arrays\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], lookback, n_features)\n",
    "# X_train_y0 = X_train_y0.reshape(X_train_y0.shape[0], lookback, n_features)\n",
    "# X_train_y1 = X_train_y1.reshape(X_train_y1.shape[0], lookback, n_features)\n",
    "X_valid = X_valid.reshape(X_valid.shape[0], lookback, n_features)\n",
    "# X_valid_y0 = X_valid_y0.reshape(X_valid_y0.shape[0], lookback, n_features)\n",
    "# X_valid_y1 = X_valid_y1.reshape(X_valid_y1.shape[0], lookback, n_features)b\n",
    "X_test = X_test.reshape(X_test.shape[0], lookback, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147004,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To Categorical Data\n",
    "\n",
    "# y_train = to_categorical(y_train)\n",
    "# y_test = to_categorical(y_test)\n",
    "# y_valid = to_categorical(y_valid)\n",
    "\n",
    "# print(y_valid.shape, y_test.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 3 1\n"
     ]
    }
   ],
   "source": [
    "n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], 1\n",
    "print(n_timesteps,n_features,n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and evaluate a model\n",
    "def evaluate_model(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    verbose, epochs, batch_size = 1, 15, 64\n",
    "    n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], y_train.shape[1]\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, input_shape=(n_timesteps,n_features)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "#     model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.add(Dense(n_outputs, activation='sigmoid'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    # fit network\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size ,validation_data=(X_valid, y_valid),verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=0)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize scores\n",
    "def summarize_results(scores):\n",
    "    print(scores)\n",
    "    m, s = np.mean(scores), np.std(scores)\n",
    "    print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run an experiment\n",
    "def run_experiment(repeats=2):\n",
    "    # repeat experiment\n",
    "    scores = list()\n",
    "    for r in range(repeats):\n",
    "        score = evaluate_model(X_train, y_train, X_test, y_test)\n",
    "        score = score * 100.0\n",
    "        print('>#%d: %.3f' % (r+1, score))\n",
    "        scores.append(score)\n",
    "    # summarize results\n",
    "    summarize_results(scores)\n",
    " \n",
    "    # run the experiment\n",
    "# run_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 147004 samples, validate on 36752 samples\n",
      "Epoch 1/15\n",
      "147004/147004 [==============================] - 111s 754us/step - loss: 0.1810 - acc: 0.9550 - val_loss: 0.1737 - val_acc: 0.9562\n",
      "Epoch 2/15\n",
      "147004/147004 [==============================] - 107s 729us/step - loss: 0.1676 - acc: 0.9571 - val_loss: 0.1693 - val_acc: 0.9568\n",
      "Epoch 3/15\n",
      "147004/147004 [==============================] - 107s 730us/step - loss: 0.1628 - acc: 0.9576 - val_loss: 0.1605 - val_acc: 0.9578\n",
      "Epoch 4/15\n",
      "147004/147004 [==============================] - 101s 688us/step - loss: 0.1584 - acc: 0.9584 - val_loss: 0.1545 - val_acc: 0.9584\n",
      "Epoch 5/15\n",
      "147004/147004 [==============================] - 102s 695us/step - loss: 0.1554 - acc: 0.9592 - val_loss: 0.1506 - val_acc: 0.9593\n",
      "Epoch 6/15\n",
      "147004/147004 [==============================] - 107s 725us/step - loss: 0.1509 - acc: 0.9602 - val_loss: 0.1456 - val_acc: 0.9604\n",
      "Epoch 7/15\n",
      "147004/147004 [==============================] - 104s 704us/step - loss: 0.1476 - acc: 0.9605 - val_loss: 0.1434 - val_acc: 0.9609\n",
      "Epoch 8/15\n",
      "147004/147004 [==============================] - 106s 718us/step - loss: 0.1454 - acc: 0.9613 - val_loss: 0.1419 - val_acc: 0.9614\n",
      "Epoch 9/15\n",
      "147004/147004 [==============================] - 104s 706us/step - loss: 0.1433 - acc: 0.9619 - val_loss: 0.1413 - val_acc: 0.9620\n",
      "Epoch 10/15\n",
      "147004/147004 [==============================] - 105s 712us/step - loss: 0.1418 - acc: 0.9621 - val_loss: 0.1367 - val_acc: 0.9624\n",
      "Epoch 11/15\n",
      " 86528/147004 [================>.............] - ETA: 1:37 - loss: 0.1388 - acc: 0.9624"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "\n",
    "verbose, epochs, batch_size = 1, 15, 64\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(n_timesteps,n_features)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "#     model.add(Dense(n_outputs, activation='softmax'))\n",
    "model.add(Dense(n_outputs, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#set early stopping monitor so the model stops training when it won't improve anymore\n",
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "\n",
    "# fit network\n",
    "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,validation_data=(X_valid, y_valid), verbose=verbose,\n",
    "                    callbacks=[early_stopping_monitor])\n",
    "\n",
    "\n",
    "# evaluate model\n",
    "accuracy = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "\n",
    "# Get current size\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "#  Set figure width to 18 and height to 4\n",
    "fig_size[0] = 18\n",
    "fig_size[1] = 4\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    " # Get current size\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "\n",
    "# Set figure width to 18 and height to 4\n",
    "fig_size[0] = 18\n",
    "fig_size[1] = 4\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model and architecture to single file\n",
    "model_2.save(\"/home_l/francovm/Projects/SSE/models/Binary_clasifier_LSTM_SSE_95.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ynew = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ynew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(ynew) # plotting by columns\n",
    "# plt.axhline(0.5)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
